# DataOps Lab 01 ‚Äì DBT & Airflow Pipeline
[![CI](https://github.com/minhhuy27/lab01-dataops/actions/workflows/ci.yml/badge.svg)](https://github.com/minhhuy27/lab01-dataops/actions/workflows/ci.yml)
[![Deploy](https://github.com/minhhuy27/lab01-dataops/actions/workflows/deploy.yml/badge.svg)](https://github.com/minhhuy27/lab01-dataops/actions/workflows/deploy.yml)

## 1. Project Overview
- M·ª•c ti√™u: x√¢y d·ª±ng pipeline DataOps tr√™n AdventureWorks2014 v·ªõi dbt (bronze/silver/gold), orchestrate b·∫±ng Airflow, ƒë√≥ng g√≥i Docker, t·ª± ƒë·ªông h√≥a CI/CD tr√™n GitHub Actions.
- Th√†nh ph·∫ßn ch√≠nh: SQL Server (AdventureWorks2014), dbt models + tests, Airflow DAG `dbt_pipeline`, Postgres metadata cho Airflow, Docker Compose, GitHub Actions.
- Lu·ªìng d·ªØ li·ªáu: SQL Server (raw) ‚Üí dbt bronze ‚Üí dbt silver ‚Üí dbt gold; Airflow g·ªçi dbt deps/run/test; CI/CD t·ª± ƒë·ªông lint/compile v√† (khi c√≥ DB) ch·∫°y dbt run/test.

## 2. System Architecture Diagram
```mermaid
flowchart LR
    subgraph gh ["GitHub Actions"]
        ci["CI: lint + dbt deps/compile"]
        deploy["Deploy: dbt deps + run/test (with DB creds) or parse fallback"]
    end

    subgraph docker ["Docker Compose"]
        sql["SQL Server\nAdventureWorks2014"]
        airflow["AIRFLOW\nDAG dbt_pipeline"]
        dbtcli["DBT CLI\n(container)"]
        pg["Postgres\nAirflow metadata"]
    end

    ext["AdventureWorks2014 .bak"] -->|"restore on start"| sql
    gh -->|pull code / trigger| docker
    airflow -->|triggers| dbtcli
    ci -->|"dbt deps/compile"| dbtcli
    deploy -->|"dbt deps + run/test when DB"| dbtcli
    deploy -->|"dbt parse fallback (no DB)"| dbtcli

    dbtcli -->|bronze models| bronze["Schema: bronze"]
    dbtcli -->|silver models| silver["Schema: silver"]
    dbtcli -->|gold models| gold["Schema: gold marts"]

    sql <-->|source tables| bronze
    bronze --> silver --> gold

    subgraph artifacts ["Artifacts"]
        docs["dbt docs"]
        logs["dbt logs"]
        manifests["manifest.json<br/>run_results.json"]
    end
    dbtcli --> docs
    dbtcli --> logs
    dbtcli --> manifests
    gh -->|upload| artifacts
```

## 3. Folder Structure
```
‚îú‚îÄ .github/workflows/           # CI (ci.yml), Deploy (deploy.yml)
‚îú‚îÄ airflow/
‚îÇ  ‚îú‚îÄ dags/                     # dbt_pipeline DAG
‚îÇ  ‚îú‚îÄ logs/                     # Airflow logs (mounted)
‚îÇ  ‚îú‚îÄ plugins/
‚îÇ  ‚îî‚îÄ Dockerfile
‚îú‚îÄ dbt/
‚îÇ  ‚îú‚îÄ models/bronze | silver | gold
‚îÇ  ‚îú‚îÄ profiles.yml             # local profile (docker dev)
‚îÇ  ‚îú‚îÄ packages.yml
‚îÇ  ‚îî‚îÄ dbt_project.yml
‚îú‚îÄ sqlserver/
‚îÇ  ‚îú‚îÄ Dockerfile               # kh·ªüi SQL Server + restore AdventureWorks2014
‚îÇ  ‚îî‚îÄ restore_db.sh
‚îú‚îÄ docker-compose.yml          # SQL Server, Postgres, Airflow, dbt
‚îú‚îÄ .sqlfluff, setup.cfg        # lint configs
‚îî‚îÄ README.md, DATAOPS_PROJECT_REQUIREMENTS.md
```

## 4. Prerequisites
- Docker & Docker Compose.
- Python (n·∫øu mu·ªën ch·∫°y dbt/linters ngo√†i container).
- Ports tr·ªëng: 1433 (SQL Server), 8080 (Airflow).
- Env t√πy ch·ªçn: `DBT_SQLSERVER_HOST/USER/PASSWORD/DATABASE/SCHEMA/DRIVER`, `SLACK_WEBHOOK_URL`.

## 5. Setup Guide (~30 ph√∫t)
1) Clone repo:
   ```bash
   git clone https://github.com/minhhuy27/Lab01-DevOps.git
   cd Lab01-DevOps
   ```
2) (T√πy ch·ªçn) t·∫°o `.env` cho SQL/Slack.
3) Ch·∫°y Docker:
   ```bash
   docker compose up -d
   ```
4) Ki·ªÉm tra services:
   - Airflow UI: http://localhost:8080 (admin/admin).
   - SQL Server: localhost:1433 (SA/YourStrong@Passw0rd).
   - dbt container: `docker compose exec dbt sh`.

## 6. Running the Pipeline
- dbt (trong container):
  ```bash
  # n·∫øu ch·∫°y l·∫ßn ƒë·∫ßu ho·∫∑c ch∆∞a c√≥ DB:
  docker compose exec sqlserver /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P YourStrong@Passw0rd -Q "RESTORE DATABASE AdventureWorks2014 FROM DISK = '/tmp/AdventureWorks2014.bak' WITH MOVE 'AdventureWorks2014_Data' TO '/var/opt/mssql/data/AdventureWorks2014.mdf', MOVE 'AdventureWorks2014_Log' TO '/var/opt/mssql/data/AdventureWorks2014_log.ldf'"

  docker compose run --rm dbt dbt deps
  docker compose run --rm dbt dbt run
  docker compose run --rm dbt dbt test
  docker compose run --rm dbt dbt source freshness
  ```
- Airflow:
  - B·∫≠t DAG `dbt_pipeline`, trigger tay trong UI.
  - Xem log trong Airflow UI ho·∫∑c th∆∞ m·ª•c `airflow/logs`.


## 7. CI/CD Summary
- CI (`ci.yml`):
  - Lint Python (black/flake8), lint SQL (sqlfluff).
  - dbt deps + compile (skip DB work), publish dbt artifacts.
  - PR validation: title format, file size, conflict markers.
- Deploy (`deploy.yml`):
  - Trigger: push `develop`/`main` ho·∫∑c manual dispatch.
  - C√†i ODBC 18, kh·ªüi SQL Server container + restore AdventureWorks2014.
  - dbt deps + compile; n·∫øu c√≥ DB secrets v√† b·∫≠t `RUN_DB_TASKS=true` s·∫Ω ch·∫°y dbt run/test, n·∫øu kh√¥ng s·∫Ω parse ƒë·ªÉ pass pipeline.
  - Upload logs/manifest; th√¥ng b√°o qua GitHub summary/commit comment (n·∫øu c√≥ quy·ªÅn); Slack n·∫øu ƒë·∫∑t webhook.
  - Rollback: dispatch v·ªõi `run_mode=rollback`.

## 8. Troubleshooting
- Kh√¥ng k·∫øt n·ªëi SQL Server: `docker compose logs sqlserver`; ki·ªÉm tra port 1433, SA password.
- Airflow scheduler kh√¥ng ch·∫°y: `docker compose logs airflow-scheduler`; ƒë·∫£m b·∫£o DB init xong.
- dbt profile l·ªói driver: rebuild image `dbt` (ODBC 18) b·∫±ng `docker compose build dbt`.
- GitHub Actions l·ªói ODBC/SQL: xem step c√†i driver & restore DB trong log CI/CD; runner c·∫ßn quy·ªÅn Docker.

## 9. DBT docs & Lineage
Sinh v√† xem t√†i li·ªáu/lineage:
```bash
docker compose exec dbt dbt deps
docker compose exec dbt dbt docs generate
docker compose exec dbt dbt docs serve --host 0.0.0.0 --port 8001
```
M·ªü http://localhost:8001 ƒë·ªÉ xem catalog v√† DBT Lineage Graph (bronze ‚Üí silver ‚Üí gold).

## 10. Contributors
- L√™ Tu·∫•n Anh - MSSV: 22120011
- Nguy·ªÖn Minh Huy - MSSV: 22120137
## 11. Monitoring (Grafana bonus)
- `docker compose up -d` d? kh?i Grafana (port 3000).
- URL: http://localhost:3000, login m?c d?nh `admin/admin`.
- Datasource d„ c‡i s?n: `Airflow Metadata` (Postgres metadata Airflow).
- Dashboard auto-provisioned: **Airflow/DBT Overview** (DAG runs by state, task instances by state, DAG runs per day) trong folder Grafana "Airflow/DBT".
- C?n c·c container `postgres`, `airflow-*`, `dbt` dang ch?y; m? port 3000.
